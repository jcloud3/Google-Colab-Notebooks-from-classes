{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled3.ipynb","provenance":[],"authorship_tag":"ABX9TyOhh3f/GFxBI2JvPspo7+Hi"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RBoCVLSBzO8d","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595007706015,"user_tz":300,"elapsed":250,"user":{"displayName":"John Cloud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdyfjLOszF3hOprvf6iyRHWHgP9QYBUjtQcUeyDA=s64","userId":"14413912309111282643"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","from scipy.linalg import block_diag\n","from cvxopt import matrix, solvers\n","solvers.options['show_progress'] = True"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"MzC7RB_AzXvG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595006635502,"user_tz":300,"elapsed":366,"user":{"displayName":"John Cloud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdyfjLOszF3hOprvf6iyRHWHgP9QYBUjtQcUeyDA=s64","userId":"14413912309111282643"}}},"source":["# Soocer Environment\n","class Soccer:\n","    def __init__(self):\n","        # initialization according to the figure 4 of the paper\n","\n","        # pos as list of 2 elements, 1st element as position of player A\n","        # 2nd element as position of player B\n","        self.pos = [np.array([0, 2]), np.array([0, 1])]\n","        self.ball = 1\n","        self.goal = [0, 3]\n","\n","\n","    def move(self, actions):\n","        # top-left corner as (0,0) origin point\n","        # 0:North, 1:East, 2:South, 3:West, 4:Stick\n","        # player can move at most one tile at a time\n","        # the index of actions map to movement at specific direction\n","        legal_actions = [[-1, 0], [0, 1], [1, 0], [0, -1], [0, 0]]\n","\n","        # players action executed in random order\n","        # mover_first as the index 0 or 1\n","        # index 0 is player A, index 1 is player B\n","        mover_first = np.random.choice([0, 1], 1)[0]\n","        mover_second = 1 - mover_first\n","\n","        # copy of current pos\n","        new_pos = self.pos.copy()\n","\n","        # scores shows the reward for player A and player B\n","        scores = np.array([0, 0])\n","\n","        # init termination status of the game\n","        done = 0\n","\n","        # check whether the received action is valid\n","        if actions[0] not in range(0,5) or actions[1] not in range(0,5):\n","            print('Invalid Action, actions shall be in [0,1,2,3,4]')\n","            return [self.pos[0][0] * 4 + self.pos[0][1], self.pos[1][0] * 4 + self.pos[1][1], self.ball], scores, done\n","        else:\n","            # moving the first player\n","            new_pos[mover_first] = self.pos[mover_first] + legal_actions[actions[mover_first]]\n","\n","            # check collision, 1st mover collides with 2nd mover after moving\n","            if (new_pos[mover_first] == self.pos[mover_second]).all():\n","                # if 1st mover possess ball, the ball is lost to 2nd mover\n","                if self.ball == mover_first:\n","                    self.ball = mover_second\n","\n","            # no collision, update 1st mover's pos\n","            elif new_pos[mover_first][0] in range(0,2) and new_pos[mover_first][1] in range(0,4):\n","                self.pos[mover_first] = new_pos[mover_first]\n","\n","                # if scored for player himself\n","                if self.pos[mover_first][1] == self.goal[mover_first] and self.ball == mover_first:      # Player scored\n","                    scores = ([1, -1][mover_first]) * np.array([100, -100])\n","                    done = 1\n","                    return [self.pos[0][0] * 4 + self.pos[0][1], self.pos[1][0] * 4 + self.pos[1][1], self.ball], scores, done\n","\n","                # if scored for the opponent\n","                elif self.pos[mover_first][1] == self.goal[mover_second] and self.ball == mover_first:\n","                    scores = ([1, -1][mover_first]) * np.array([-100, 100])\n","                    done = 1\n","                    return [self.pos[0][0] * 4 + self.pos[0][1], self.pos[1][0] * 4 + self.pos[1][1], self.ball], scores, done\n","\n","\n","            # moving the second player\n","            new_pos[mover_second] = self.pos[mover_second] + legal_actions[actions[mover_second]]\n","\n","            # check collision, 2nd mover collides with 1st mover after moving\n","            if (new_pos[mover_second] == self.pos[mover_first]).all():  # Collide\n","                # if 2nd mover possess ball, the ball is lost to 1st mover\n","                if self.ball == mover_second:\n","                    self.ball = mover_first\n","\n","            # no collision, update 2nd mover's pos\n","            elif new_pos[mover_second][0] in range(0,2) and new_pos[mover_second][1] in range(0,4):\n","                self.pos[mover_second] = new_pos[mover_second]\n","\n","                # if scored for player himself\n","                if self.pos[mover_second][1] == self.goal[mover_second] and self.ball == mover_second:\n","                    scores = ([1, -1][mover_second]) * np.array([100, -100])\n","                    done = 1\n","                    return [self.pos[0][0] * 4 + self.pos[0][1], self.pos[1][0] * 4 + self.pos[1][1], self.ball], scores, done\n","\n","                # if scored for the opponent\n","                elif self.pos[mover_second][1] == self.goal[mover_first] and self.ball == mover_second:\n","                    scores = np.array([-100, 100]) * [1, -1][mover_second]\n","                    done = 1\n","                    return [self.pos[0][0] * 4 + self.pos[0][1], self.pos[1][0] * 4 + self.pos[1][1], self.ball], scores, done\n","\n","\n","        return [self.pos[0][0] * 4 + self.pos[0][1], self.pos[1][0] * 4 + self.pos[1][1], self.ball], scores, done"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"g_rj-C22zIfT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595007887102,"user_tz":300,"elapsed":382,"user":{"displayName":"John Cloud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdyfjLOszF3hOprvf6iyRHWHgP9QYBUjtQcUeyDA=s64","userId":"14413912309111282643"}}},"source":["# Foe-Q Learning\n","def Foe_Q(no_steps = int(10)):\n","\n","    # Take action with epsilon-greedy\n","    def generate_action(pi, state, i):\n","        # epsilon-greey to take best action from action-value function\n","        # decay epsilon\n","        epsilon = epsilon_decay ** i\n","        if np.random.random() < epsilon:\n","            return np.random.choice([0,1,2,3,4], 1)[0]\n","        else:\n","            return np.random.choice([0,1,2,3,4], 1, p=pi[state[0]][state[1]][state[2]])[0]\n","\n","    # same formulation as hw6\n","    # Q value is just like the reward matrix\n","    def max_min(Q, state):\n","        c = matrix([-1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n","        G = matrix(np.append(np.append(np.ones((5,1)), -Q[state[0]][state[1]][state[2]], axis=1), np.append(np.zeros((5,1)), -np.eye(5), axis=1), axis=0))\n","        h = matrix([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n","        A = matrix([[0.0],[1.0], [1.0], [1.0], [1.0], [1.0]])\n","        b = matrix(1.0)\n","        sol = solvers.lp(c=c, G=G, h=h, A=A, b=b)\n","        return np.abs(sol['x'][1:]).reshape((5,)) / sum(np.abs(sol['x'][1:])), np.array(sol['x'][0])\n","\n","    # discount factor\n","    gamma = 0.9\n","\n","    # Define the epsilon and its decay for epsilon-greedy action selection\n","    epsilon_min = 0.001\n","    epsilon_decay = 10**(np.log10(epsilon_min)/no_steps)\n","    # epsilon_min = 0.001\n","    # epsilon_decay = 0.999995\n","\n","    # learning rate\n","    alpha = 1.0\n","    alpha_min = 0.001\n","    alpha_decay = 10**(np.log10(alpha_min)/no_steps)\n","\n","\n","    # Q_tables of player A and player B\n","    # the state-action space is 8 (pos for player A) * 8 (pos for player B) * 2 (ball possession) * 5 (valid actions for player A) * 5 (valid actions for player B)\n","    # initialization to 1 in order to break from zero\n","    Q_1 = np.ones((8, 8, 2, 5, 5)) * 1.0\n","    Q_2 = np.ones((8, 8, 2, 5, 5)) * 1.0\n","\n","    # init policy for player 1 and player 2\n","    Pi_1 = np.ones((8, 8, 2, 5)) * 1/5\n","    Pi_2 = np.ones((8, 8, 2, 5)) * 1/5\n","\n","    # value of states, only depends on pos of players and possession of ball\n","    V_1 = np.ones((8, 8, 2)) * 1.0\n","    V_2 = np.ones((8, 8, 2)) * 1.0\n","\n","    # error list to store ERR\n","    errors_list = []\n","\n","    # set seed\n","    np.random.seed(1234)\n","\n","    # Loop for no_steps steps\n","    start_time = time.time()\n","    i = 0\n","\n","    while i < no_steps:\n","        soccer = Soccer()\n","        state = [soccer.pos[0][0] * 4 + soccer.pos[0][1], soccer.pos[1][0] * 4 + soccer.pos[1][1], soccer.ball]\n","        done = 0\n","        while not done:\n","            if i % 1000 == 0:\n","                print('\\rstep {}\\t Time: {:.2f} \\t Percentage: {:.2f}% \\t Alpha: {:.3f}'.format(i, time.time() - start_time, i*100/no_steps, alpha), end=\"\")\n","            i += 1\n","\n","            # player A at sate S take action South before update\n","            # first index is player A's position index (0-7), 2 is frist row (0), 3rd column\n","            # second index is player B's position index (0-7), 1 is first row (0), 2nd column\n","            # third index is ball possession, according to graph, B has the ball\n","            # fourth index is action from player B, B sticks\n","            # fifth index is action from player A, A goes south\n","            # rationale for putting player A's action as last index is for easy handling of max function (put the last dimention as player's action rather than opponent's action)\n","            before = Q_1[2][1][1][4][2]\n","\n","            # eps-greedy to generate action\n","            actions = [generate_action(Pi_1, state, i), generate_action(Pi_2, state, i)]\n","\n","            # get next state, reward and game termination flag\n","            state_prime, rewards, done = soccer.move(actions)\n","\n","            # Q-learning update\n","            Q_1[state[0]][state[1]][state[2]][actions[1]][actions[0]] = (1 - alpha) * Q_1[state[0]][state[1]][state[2]][actions[1]][actions[0]] + alpha * (rewards[0] + gamma * V_1[state_prime[0]][state_prime[1]][state_prime[2]])\n","\n","            # use LP to solve maxmin\n","            pi, val = max_min(Q_1, state)\n","            Pi_1[state[0]][state[1]][state[2]] = pi\n","            V_1[state[0]][state[1]][state[2]] = val\n","\n","            # Q-learning update\n","            Q_2[state[0]][state[1]][state[2]][actions[0]][actions[1]] = (1 - alpha) * Q_2[state[0]][state[1]][state[2]][actions[0]][actions[1]] + alpha * (rewards[1] + gamma * V_2[state_prime[0]][state_prime[1]][state_prime[2]])\n","\n","            # use LP to solve maxmin\n","            pi, val = max_min(Q_2, state)\n","            Pi_2[state[0]][state[1]][state[2]] = pi\n","            V_2[state[0]][state[1]][state[2]] = val\n","            state = state_prime\n","\n","            # compute ERR\n","            after = Q_1[2][1][1][4][2]\n","            errors_list.append(np.abs(after - before))\n","\n","            # decay learning rate\n","            alpha = alpha_decay ** i\n","\n","    return errors_list, Q_1, Q_2, V_1, V_2, Pi_1, Pi_2"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"85EyOR8bzqku","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595007856478,"user_tz":300,"elapsed":63332,"user":{"displayName":"John Cloud","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgdyfjLOszF3hOprvf6iyRHWHgP9QYBUjtQcUeyDA=s64","userId":"14413912309111282643"}},"outputId":"e7ad51a6-5540-4041-e6a0-80f9a9137f57"},"source":["foe_q_errors, Q_1_foe, Q_2_foe, V_1_foe, V_2_foe, Pi_1_foe, Pi_2_foe = Foe_Q()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["step 10000\t Time: 62.96 \t Percentage: 100.00% \t Alpha: 0.001"],"name":"stdout"}]}]}